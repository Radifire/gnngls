{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "norman-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crucial-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import networkx as nx\n",
    "import tqdm.auto as tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "import socket\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import dgl.nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominant-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.get_visible_devices('GPU')\n",
    "is_gpu_available = len(gpus) > 0\n",
    "if is_gpu_available:\n",
    "    device = gpus[0]\n",
    "else:\n",
    "    cpus = tf.config.get_visible_devices('CPU')\n",
    "    device = cpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moral-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "class Net(tf.keras.Model):\n",
    "    def __init__(self, in_size, out_size, hidden_size, n_hidden=1, n_heads=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.msg_layers = [dgl.nn.GATConv(in_size, hidden_size, num_heads=self.n_heads, activation=tf.keras.activations.relu)]\n",
    "        for _ in range(n_hidden - 1):\n",
    "            self.msg_layers += [\n",
    "                dgl.nn.GATConv(hidden_size*self.n_heads, hidden_size, num_heads=self.n_heads, activation=tf.keras.activations.relu),\n",
    "            ]\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(out_size, activation=tf.keras.activations.relu)\n",
    "        \n",
    "    def call(self, g, h, training=False):        \n",
    "        for l in self.msg_layers:\n",
    "            h = l(g, h)\n",
    "            h = tf.reshape(h, (-1, self.hidden_size*self.n_heads))\n",
    "            \n",
    "        h = self.output_layer(h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "net = Net(18, 2, 64, n_hidden=3, n_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arabic-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = os.environ['DGLBACKEND']\n",
    "dgl_graphs, _ = dgl.data.utils.load_graphs(f'../data/dgl_graphs_{framework}.bin')\n",
    "nx_graphs = nx.read_gpickle(f'../data/nx_graphs_{framework}.pkl')\n",
    "\n",
    "dataset = list(zip(dgl_graphs, nx_graphs))\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, train_size=0.7, shuffle=True)\n",
    "train_set, val_set = train_test_split(train_set, train_size=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reserved-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, _ = map(list, zip(*train_set))\n",
    "val_set, _ = map(list, zip(*val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "judicial-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "net = Net(18, 2, 64, n_hidden=3, n_heads=2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy(name='loss')\n",
    "\n",
    "# https://stackoverflow.com/a/8290508/2426888\n",
    "def batch_iterable(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "likely-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "filled-secondary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op CreateSummaryFileWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a76511dbf4f488ebb6f8f22360f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "Cannot assign node feature \"e\" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-375f889c8f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dgl-gpu/lib/python3.8/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(graphs, ndata, edata, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# we allow empty graphs to have no features during batching.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mret_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_feat_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nodes[\"{}\"].data'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mretg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Batch edge feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dgl-gpu/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, other, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dgl-gpu/lib/python3.8/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;34m'The HeteroNodeDataView has only one node type. '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34m'please pass a tensor directly'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dgl-gpu/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m_set_n_repr\u001b[0;34m(self, ntid, u, data)\u001b[0m\n\u001b[1;32m   3809\u001b[0m                                ' Got %d and %d instead.' % (nfeats, num_nodes))\n\u001b[1;32m   3810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3811\u001b[0;31m                 raise DGLError('Cannot assign node feature \"{}\" on device {} to a graph on'\n\u001b[0m\u001b[1;32m   3812\u001b[0m                                \u001b[0;34m' device {}. Call DGLGraph.to() to copy the graph to the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3813\u001b[0m                                ' same device.'.format(key, F.context(val), self.device))\n",
      "\u001b[0;31mDGLError\u001b[0m: Cannot assign node feature \"e\" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device."
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "file_name = '{}_{}_{}'.format(datetime.datetime.now().strftime('%b%d_%H-%M-%S'), socket.gethostname(), framework)\n",
    "writer = tf.summary.create_file_writer(logdir='runs/' + file_name)\n",
    "\n",
    "pbar = tqdm.trange(n_epochs)\n",
    "with writer.as_default():\n",
    "    for epoch in pbar:\n",
    "\n",
    "        random.shuffle(train_set)\n",
    "        epoch_loss = 0\n",
    "        for batch_i, batch in enumerate(batch_iterable(train_set, n=batch_size)):\n",
    "            batch = dgl.batch(batch).to(device)\n",
    "            x = batch.ndata['x']\n",
    "            y = batch.ndata['y']\n",
    "\n",
    "            pos_weight = len(y)/tf.math.reduce_sum(y) - 1\n",
    "            w = np.ones(len(y))\n",
    "            w[tf.squeeze(y) == 1] = pos_weight\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = net(batch, x)\n",
    "                loss = criterion(y, y_pred, sample_weight=w)\n",
    "            grads = tape.gradient(loss, net.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
    "\n",
    "            epoch_loss += loss\n",
    "\n",
    "        epoch_loss /= (batch_i + 1)\n",
    "        tf.summary.scalar(\"Loss/train\", epoch_loss, step=epoch)\n",
    "\n",
    "        # Validation\n",
    "        batch = dgl.batch(val_set)\n",
    "\n",
    "        x = batch.ndata['x']\n",
    "        y = batch.ndata['y']\n",
    "        \n",
    "        pos_weight = len(y)/tf.math.reduce_sum(y) - 1\n",
    "        w = np.ones(len(y))\n",
    "        w[tf.squeeze(y) == 1] = pos_weight\n",
    "        \n",
    "        y_pred = net(batch, x)\n",
    "        val_loss = criterion(y, y_pred, sample_weight=w)\n",
    "        tf.summary.scalar(\"Loss/validation\", val_loss, step=epoch)\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Train Loss': '{:.4f}'.format(epoch_loss),\n",
    "            'Validation Loss': '{:.4f}'.format(val_loss),\n",
    "        })\n",
    "    \n",
    "        writer.flush()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-endorsement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
