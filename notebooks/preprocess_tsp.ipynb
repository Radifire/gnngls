{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excited-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "backend = 'pytorch'\n",
    "os.environ['DGLBACKEND'] = backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "going-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import tensorflow as tf\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import tqdm.auto as tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-folder",
   "metadata": {},
   "source": [
    "# Parse solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entire-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "with open('../data/tsp10_concorde_2000.txt') as data_file:\n",
    "    for line in data_file:\n",
    "        problem_str, solution_str = line.split('output')\n",
    "\n",
    "        node_data = iter(problem_str.strip().split(' '))\n",
    "        node_counter = 0\n",
    "        nodes = {}\n",
    "        for x in node_data:\n",
    "            y = next(node_data)\n",
    "            pos = np.array([float(x), float(y)])\n",
    "            nodes[node_counter] = pos\n",
    "            node_counter += 1\n",
    "\n",
    "        solution = [int(x) - 1 for x in solution_str.strip().split(' ')]\n",
    "        solution_edges = [e for e in zip(solution[:-1], solution[1:])]\n",
    "\n",
    "        offset = len(G.nodes)\n",
    "        for i in nodes:\n",
    "            G.add_node(offset + i, x=nodes[i][0], y=nodes[i][1])\n",
    "        for i, j in itertools.combinations(nodes, 2):\n",
    "            w = np.linalg.norm(nodes[i] - nodes[j])\n",
    "            in_solution = (i, j) in solution_edges or (j, i) in solution_edges\n",
    "            G.add_edge(offset + i, offset + j, in_solution=in_solution, weight=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-halloween",
   "metadata": {},
   "source": [
    "# Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tour(g, depot, weight='weight'):\n",
    "    tour = [depot]\n",
    "    while len(tour) < len(g.nodes):\n",
    "        i = tour[-1]\n",
    "        neighbours = [(j, g.edges[(i, j)]['weight']) for j in g.neighbors(i) if j not in tour]\n",
    "        j, dist = min(neighbours, key=lambda e: e[1])\n",
    "        tour.append(j)\n",
    "\n",
    "    tour.append(depot)\n",
    "    return tour\n",
    "\n",
    "def set_greedy_tour(g, depot):\n",
    "    tour = greedy_tour(g, depot)\n",
    "    tour_edges = zip(tour[:-1], tour[1:])\n",
    "\n",
    "    nx.set_edge_attributes(g, False, 'in_greedy_solution')\n",
    "    for e in tour_edges:\n",
    "        g.edges[e]['in_greedy_solution'] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_neighbour_features(g, nn_levels, min_degree):\n",
    "    # calculate knn for each edge\n",
    "    for e in g.edges:\n",
    "        g.edges[e]['neighbour'] = {}\n",
    "\n",
    "    for i in g.nodes:\n",
    "        neighbours = [(j, g.edges[(i, j)]['weight']) for j in g.neighbors(i)]\n",
    "        nearest_neighbours = sorted(neighbours, key=lambda e: e[1])\n",
    "        for k, (j, _) in enumerate(nearest_neighbours):\n",
    "            g.edges[(i, j)]['neighbour'][i] = k\n",
    "            \n",
    "    # knn graphs and nn clique\n",
    "    nx.set_edge_attributes(g, False, 'nn_clique')\n",
    "    for i, level in enumerate(nn_levels):\n",
    "        nx.set_edge_attributes(g, False, f'{i}_nn')\n",
    "\n",
    "    for e in g.edges:\n",
    "        i, j = e\n",
    "        neighbours = g.edges[e]['neighbour']\n",
    "        if neighbours[i] == neighbours[j]:\n",
    "            g.edges[e]['nn_clique'] = True\n",
    "\n",
    "        for level_i, level in enumerate(nn_levels):\n",
    "            g.edges[(i, j)][f'{level_i}_nn'] = (neighbours[i] <= level) or (neighbours[j] <= level)\n",
    "            \n",
    "    # erode longest edges until min degree reached\n",
    "    edges = sorted([(e, g.edges[e]['weight']) for e in g.edges], key=lambda e: e[1], reverse=True)\n",
    "    edges, _ = map(list, zip(*edges))\n",
    "\n",
    "    h = g.edge_subgraph(edges)\n",
    "    while min(dict(nx.degree(h)).values()) > min_degree:\n",
    "        edges.pop(0)\n",
    "        h = g.edge_subgraph(edges)\n",
    "\n",
    "    nx.set_edge_attributes(g, False, 'md_nn')\n",
    "    for e in edges:\n",
    "        g.edges[e]['md_nn'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dated-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_depot_weight(g, depot):\n",
    "    for n in g.nodes:\n",
    "        if n == depot:\n",
    "            g.nodes[n]['depot_weight'] = 0\n",
    "        else:\n",
    "            g.nodes[n]['depot_weight'] = g.edges[(depot, n)]['weight']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_fancy_graph_features(g):\n",
    "    cf_bc = nx.edge_current_flow_betweenness_centrality(g, weight='weight')\n",
    "    sp_bc = nx.edge_betweenness_centrality(g, weight='weight')\n",
    "\n",
    "    sp_cc = nx.closeness_centrality(g, distance='weight')\n",
    "    cf_cc = nx.current_flow_closeness_centrality(g, weight='weight')\n",
    "    cl = nx.clustering(g, weight='weight')\n",
    "\n",
    "    nx.set_edge_attributes(g, sp_bc, 'sp_betweenness')\n",
    "    nx.set_edge_attributes(g, cf_bc, 'cf_betweenness')\n",
    "    nx.set_node_attributes(g, sp_cc, 'sp_closeness')\n",
    "    nx.set_node_attributes(g, cf_cc, 'cf_closeness')\n",
    "    nx.set_node_attributes(g, cl, 'clustering')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-trustee",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "logical-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c117294e1c4fa7a164ebccd525bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for nodes in tqdm.tqdm(nx.connected_components(G)):\n",
    "    g = G.subgraph(nodes)\n",
    "\n",
    "    depot = next(iter(g.nodes))\n",
    "    set_greedy_tour(g, depot)\n",
    "    set_depot_weight(g, depot)\n",
    "\n",
    "    nn_levels = [int(x*len(g.nodes)) for x in [0.1, 0.2, 0.3]]\n",
    "    min_degree = 2\n",
    "    set_neighbour_features(g, nn_levels, min_degree)\n",
    "\n",
    "    set_fancy_graph_features(g)\n",
    "    \n",
    "    for e in g.edges:\n",
    "        i, j = e\n",
    "        features = np.array([\n",
    "            g.edges[e]['weight'],\n",
    "            g.edges[e]['in_greedy_solution'],\n",
    "            g.edges[e]['neighbour'][i],\n",
    "            g.edges[e]['neighbour'][j],\n",
    "            g.edges[e]['nn_clique'],\n",
    "            g.edges[e]['0_nn'],\n",
    "            g.edges[e]['1_nn'],\n",
    "            g.edges[e]['2_nn'],\n",
    "            g.edges[e]['md_nn'],\n",
    "#             g.edges[e]['sp_betweenness'], # the same for every node\n",
    "            g.edges[e]['cf_betweenness'],\n",
    "            g.nodes[i]['depot_weight'],\n",
    "            g.nodes[j]['depot_weight'],\n",
    "            g.nodes[i]['sp_closeness'],\n",
    "            g.nodes[j]['sp_closeness'],\n",
    "            g.nodes[i]['cf_closeness'],\n",
    "            g.nodes[j]['cf_closeness'],\n",
    "            g.nodes[i]['clustering'],\n",
    "            g.nodes[j]['clustering'],\n",
    "        ], dtype=np.float32)\n",
    "        label = np.array([\n",
    "            g.edges[e]['in_solution'],\n",
    "        ]).astype(np.int64)\n",
    "        \n",
    "        g.edges[e]['x'] = features\n",
    "        g.edges[e]['y'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "going-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(np.vstack([g.edges[e]['x'] for e in g.edges]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "republican-penetration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e87fc8d78e3496ca0b089500acc32ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dgl_graphs = []\n",
    "nx_graphs = []\n",
    "\n",
    "for nodes in tqdm.tqdm(nx.connected_components(G)):\n",
    "    g = G.subgraph(nodes)\n",
    "    lg = nx.line_graph(g)\n",
    "    lg.add_edges_from(zip(lg.nodes, lg.nodes))\n",
    "    \n",
    "    for e_i, e in enumerate(lg.nodes):\n",
    "        features = g.edges[e]['x']\n",
    "        label = g.edges[e]['y']\n",
    "        lg.nodes[e]['x'] = scaler.transform(features[np.newaxis, :]).squeeze()\n",
    "        lg.nodes[e]['y'] = label\n",
    "        lg.nodes[e]['e'] = e\n",
    "        \n",
    "    dgl_g = dgl.from_networkx(lg, node_attrs=['x', 'y', 'e'])\n",
    "    \n",
    "    dgl_graphs.append(dgl_g)\n",
    "    nx_graphs.append(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "induced-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl.data.utils.save_graphs(f'../data/dgl_graphs_{backend}.bin', dgl_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "transparent-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(nx_graphs, f'../data/nx_graphs_{backend}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-breast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
